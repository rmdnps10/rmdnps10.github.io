{"componentChunkName":"component---src-templates-blog-post-js","path":"/rag-core-concept/","result":{"data":{"site":{"siteMetadata":{"title":"í™ˆ","siteUrl":"https://inyoung.dev","author":{"name":"Inyoung Chung"}}},"allMarkdownRemark":{"nodes":[{"fields":{"slug":"/boj-1106-hotel/"},"frontmatter":{"title":"[ë°±ì¤€ JAVA] í˜¸í…” 1106 ë¨¸ë¦¿ì†ì— ë°•ì•„ë„£ê¸°","date":"2026-02-20","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ffffff"}},{"fields":{"slug":"/http-advanced-features/"},"frontmatter":{"title":"[ë„¤íŠ¸ì›Œí¬] HTTPì˜ ì‘ìš© - ì¿ í‚¤, ìºì‹œ, ë³´ì•ˆ","date":"2026-02-17","tags":["ë„¤íŠ¸ì›Œí¬"],"pointColor":"#ffffff"}},{"fields":{"slug":"/http-fundamentals/"},"frontmatter":{"title":"[ë„¤íŠ¸ì›Œí¬] HTTPì˜ ê¸°ì´ˆ - DNSì™€ HTTP Message, Method, Status (ìŠ¤ì•• ì£¼ì˜) ","date":"2026-02-16","tags":["ë„¤íŠ¸ì›Œí¬"],"pointColor":"#ffffff"}},{"fields":{"slug":"/transport-layer-tcp-udp/"},"frontmatter":{"title":"[ë„¤íŠ¸ì›Œí¬] ì „ì†¡ ê³„ì¸µ - TCPì™€ UDP","date":"2026-02-15","tags":["ë„¤íŠ¸ì›Œí¬"],"pointColor":"#ffffff"}},{"fields":{"slug":"/network-layer-ip-protocol/"},"frontmatter":{"title":"[ë„¤íŠ¸ì›Œí¬] ë„¤íŠ¸ì›Œí¬ ê³„ì¸µê³¼ IP í”„ë¡œí† ì½œ","date":"2026-02-14","tags":["ë„¤íŠ¸ì›Œí¬"],"pointColor":"#ffffff"}},{"fields":{"slug":"/physical-and-data-link-layer/"},"frontmatter":{"title":"[ë„¤íŠ¸ì›Œí¬] ë¬¼ë¦¬ ê³„ì¸µê³¼ ë°ì´í„° ë§í¬ ê³„ì¸µ - ì´ë”ë„·ê³¼ ë„¤íŠ¸ì›Œí¬ ì¥ë¹„","date":"2026-02-13","tags":["ë„¤íŠ¸ì›Œí¬"],"pointColor":"#ffffff"}},{"fields":{"slug":"/network-big-picture/"},"frontmatter":{"title":"[ë„¤íŠ¸ì›Œí¬] ë„¤íŠ¸ì›Œí¬ì˜ í° ê·¸ë¦¼","date":"2026-02-12","tags":["ë„¤íŠ¸ì›Œí¬"],"pointColor":"#ffffff"}},{"fields":{"slug":"/troubleshooting-supabase-auth/"},"frontmatter":{"title":"[íŠ¸ëŸ¬ë¸”ìŠˆíŒ…] Supabase Authë¥¼ í™œìš©í•œ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œì˜ ì„¸ì…˜ ìœ ì§€","date":"2026-02-10","tags":["Web","íšŒê³ "],"pointColor":"#3ECF8D"}},{"fields":{"slug":"/waterfall-agile/"},"frontmatter":{"title":"[ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™] Waterfallê³¼ Agile","date":"2026-02-03","tags":["ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™"],"pointColor":"#ffffff"}},{"fields":{"slug":"/os-file-system/"},"frontmatter":{"title":"[ìš´ì˜ì²´ì œ] íŒŒì¼ ì‹œìŠ¤í…œ","date":"2026-01-27","tags":["ìš´ì˜ì²´ì œ"],"pointColor":"#ffffff"}},{"fields":{"slug":"/os-virtual-memory/"},"frontmatter":{"title":"[ìš´ì˜ì²´ì œ] 5. ê°€ìƒ ë©”ëª¨ë¦¬","date":"2026-01-26","tags":["ìš´ì˜ì²´ì œ"],"pointColor":"#ffffff"}},{"fields":{"slug":"/os-cpu-scheduling/"},"frontmatter":{"title":"[ìš´ì˜ì²´ì œ] 4. CPU ìŠ¤ì¼€ì¤„ë§","date":"2026-01-25","tags":["ìš´ì˜ì²´ì œ"],"pointColor":"#ffffff"}},{"fields":{"slug":"/os-synchronization-deadlock/"},"frontmatter":{"title":"[ìš´ì˜ì²´ì œ] 3. ë™ê¸°í™”ì™€ êµì°© ìƒíƒœ","date":"2026-01-24","tags":["ìš´ì˜ì²´ì œ"],"pointColor":"#ffffff"}},{"fields":{"slug":"/os-process-thread/"},"frontmatter":{"title":"[ìš´ì˜ì²´ì œ] 2. í”„ë¡œì„¸ìŠ¤ì™€ ìŠ¤ë ˆë“œ","date":"2026-01-23","tags":["ìš´ì˜ì²´ì œ"],"pointColor":"#ffffff"}},{"fields":{"slug":"/os-big-picture/"},"frontmatter":{"title":"[ìš´ì˜ì²´ì œ] 1. ìš´ì˜ì²´ì œì˜ í° ê·¸ë¦¼","date":"2026-01-21","tags":["ìš´ì˜ì²´ì œ"],"pointColor":"#ffffff"}},{"fields":{"slug":"/computer-architecture-cpu/"},"frontmatter":{"title":"[ì»´í“¨í„°êµ¬ì¡°] 3. CPU","date":"2026-01-18","tags":["ì»´í“¨í„°êµ¬ì¡°"],"pointColor":"#ffffff"}},{"fields":{"slug":"/computer-architecture-computer-information/"},"frontmatter":{"title":"[ì»´í“¨í„°êµ¬ì¡°] 2. ì»´í“¨í„°ê°€ ì´í•´í•˜ëŠ” ì •ë³´","date":"2026-01-17","tags":["ì»´í“¨í„°êµ¬ì¡°"],"pointColor":"#ffffff"}},{"fields":{"slug":"/computer-architecture-big-picture/"},"frontmatter":{"title":"[ì»´í“¨í„°êµ¬ì¡°] 1. ì»´í“¨í„°êµ¬ì¡°ì˜ í° ê·¸ë¦¼","date":"2026-01-15","tags":["ì»´í“¨í„°êµ¬ì¡°"],"pointColor":"#ffffff"}},{"fields":{"slug":"/java-coding-test-grammer/"},"frontmatter":{"title":"Java ì½”ë”©í…ŒìŠ¤íŠ¸ ë¬¸ë²• ìµœì¢… ì •ë¦¬","date":"2026-01-08","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ed8b00"}},{"fields":{"slug":"/lg-webos-tv-fullstack-appliaction/"},"frontmatter":{"title":"WebOS TVì— ë“¤ì–´ê°ˆ í’€ìŠ¤íƒ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ì–´ë³´ì (LGì „ì ì‚°í•™ í”„ë¡œì íŠ¸ í›„ê¸°)","date":"2025-12-22","tags":["íšŒê³ "],"pointColor":"#ffffff"}},{"fields":{"slug":"/algorithm-maximum-flow/"},"frontmatter":{"title":"ì•Œê³ ë¦¬ì¦˜ì„¤ê³„ì™€ë¶„ì„ - ìµœëŒ€ ìœ ëŸ‰ ë¬¸ì œ (Maximum Flow)","date":"2025-12-16","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ffffff"}},{"fields":{"slug":"/algorithm-shortest-path/"},"frontmatter":{"title":"ì•Œê³ ë¦¬ì¦˜ì„¤ê³„ì™€ë¶„ì„ - ìµœë‹¨ê²½ë¡œ (Shortest Path)","date":"2025-12-13","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ffffff"}},{"fields":{"slug":"/algorithm-minimum-spanning-tree/"},"frontmatter":{"title":"ì•Œê³ ë¦¬ì¦˜ì„¤ê³„ì™€ë¶„ì„ - MST (ìµœì†Œì‹ ì¥íŠ¸ë¦¬)","date":"2025-12-12","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ffffff"}},{"fields":{"slug":"/algorithm-bfs-dfs/"},"frontmatter":{"title":"BFS/DFSì™€ Topological Sort","date":"2025-12-11","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ffffff"}},{"fields":{"slug":"/algorithm-greedy-algorithm/"},"frontmatter":{"title":"ì•Œê³ ë¦¬ì¦˜ì„¤ê³„ì™€ë¶„ì„ - Greedy algorithm (ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜)","date":"2025-12-10","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ffffff"}},{"fields":{"slug":"/algorithm-dynamic-programming/"},"frontmatter":{"title":"ì•Œê³ ë¦¬ì¦˜ì„¤ê³„ì™€ë¶„ì„ - Dynamic Programming (ë™ì  ê³„íšë²•)","date":"2025-12-07","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ffffff"}},{"fields":{"slug":"/algorithm-binary-search-tree/"},"frontmatter":{"title":"ì•Œê³ ë¦¬ì¦˜ì„¤ê³„ì™€ë¶„ì„ - Binary Search Tree (ì´ì§„ íƒìƒ‰ íŠ¸ë¦¬)","date":"2025-12-05","tags":["ì•Œê³ ë¦¬ì¦˜"],"pointColor":"#ffffff"}},{"fields":{"slug":"/database-system-erd/"},"frontmatter":{"title":"ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ ê°œë¡  ğŸ“š - Chapter2. ERDë¡œ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„í•˜ê¸°","date":"2025-10-05","tags":["DB"],"pointColor":"#ffffff"}},{"fields":{"slug":"/make-huggingface-pipeline/"},"frontmatter":{"title":"í—ˆê¹…í˜ì´ìŠ¤ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ì–´ë³´ì - íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ í™œìš© ê°€ì´ë“œ","date":"2025-10-04","tags":["AI"],"pointColor":"#FF9A00"}},{"fields":{"slug":"/rag-core-concept/"},"frontmatter":{"title":"RAGì˜ í•µì‹¬ ê°œë…ê³¼ ì‹¤ìŠµ","date":"2025-10-01","tags":["AI"],"pointColor":"#FF6B6B"}},{"fields":{"slug":"/prompt-engineering-basic/"},"frontmatter":{"title":"í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ - AIì™€ íš¨ê³¼ì ìœ¼ë¡œ ì†Œí†µí•˜ëŠ” ë°©ë²•","date":"2025-09-28","tags":["AI"],"pointColor":"#ffffff"}},{"fields":{"slug":"/how-to-use-flutter-riverpod/"},"frontmatter":{"title":"ì´ˆì‹¬ì ì…ì¥ì—ì„œ Flutter Riverpodì„ 'ì˜' ì‚¬ìš©í•˜ëŠ” ë°©ë²• (ì¥ë¬¸)","date":"2025-09-20","tags":["Flutter"],"pointColor":"#0468d7"}},{"fields":{"slug":"/database-system-introduction/"},"frontmatter":{"title":"ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ ê°œë¡  ğŸ“š â€“ Chapter 1. Introduction of Database Systems","date":"2025-09-16","tags":["DB"],"pointColor":"#ffffff"}},{"fields":{"slug":"/kakaobank-devrel-internship-retrospect/"},"frontmatter":{"title":"ì„œë¹„ìŠ¤ ê°œë°œë¶€í„° DevRelê¹Œì§€: ì¹´ì¹´ì˜¤ë±…í¬ ì¸í„´ì‰½ íšŒê³ ","date":"2025-07-28","tags":["ì¸í„´","íšŒê³ ","ì¹´ì¹´ì˜¤ë±…í¬","ë„¤ì´ë²„ë©ìŠ¤"],"pointColor":"#ffe300"}},{"fields":{"slug":"/my-it-startup-internship-retrospect/"},"frontmatter":{"title":"ë‚˜ì˜ IT ìŠ¤íƒ€íŠ¸ì—… ì¸í„´ì‰½ íšŒê³ ","date":"2025-03-14","tags":["ì¸í„´","íšŒê³ "],"pointColor":"#6FE7FF"}},{"fields":{"slug":"/sogang-likelion-management-retrospect/"},"frontmatter":{"title":"ì„œê°•ëŒ€í•™êµ ë©‹ìŸì´ì‚¬ìì²˜ëŸ¼ ìš´ì˜ì§„ íšŒê³ ","date":"2025-02-27","tags":["ë©‹ìŸì´ì‚¬ìì²˜ëŸ¼","íšŒê³ "],"pointColor":"#FD7911"}}]},"markdownRemark":{"id":"464044b0-2b70-5b20-aa99-3adf6538535c","excerpt":"ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ì‹¤ì‹œê°„ ì •ë³´ í™œìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” RAG ê¸°ìˆ ì´ ì£¼ëª©ë°›ê³  ìˆë‹¤. ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ ì´ í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì„ ì´ë¡ ë¶€í„° ì‹¤ìŠµê¹Œì§€ ì•Œì•„ë³´ì. 1ï¸âƒ£ RAGë€? 1-1 RAGâ€¦","html":"<blockquote>\n<p>ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ì‹¤ì‹œê°„ ì •ë³´ í™œìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” RAG ê¸°ìˆ ì´ ì£¼ëª©ë°›ê³  ìˆë‹¤. ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ ì´ í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì„ ì´ë¡ ë¶€í„° ì‹¤ìŠµê¹Œì§€ ì•Œì•„ë³´ì.</p>\n</blockquote>\n<h2 id=\"1ï¸-ragë€\">1ï¸âƒ£ RAGë€?</h2>\n<h4 id=\"1-1-ragì˜-ì •ì˜\">1-1 RAGì˜ ì •ì˜</h4>\n<p><code class=\"language-text\">RAG(Retrieval-Augmented Generation)</code>ëŠ” ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê¸°ìˆ ë¡œ <strong>ì •ë³´ ê²€ìƒ‰ì„ í†µí•´</strong> ì–¸ì–´ ìƒì„± ê³¼ì •ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ì‹ì´ë‹¤.</p>\n<p>ê¸°ì¡´ ì–¸ì–´ ëª¨ë¸ì´ ì‚¬ì „ í•™ìŠµëœ ì§€ì‹ì—ë§Œ ì˜ì¡´í•˜ëŠ” ë°˜ë©´, RAGëŠ” ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ë” ì •í™•í•˜ê³  ìµœì‹ ì˜ ë‹µë³€ì„ ìƒì„±í•œë‹¤.</p>\n<h4 id=\"1-2-rag-ì‘ë™-ì›ë¦¬\">1-2 RAG ì‘ë™ ì›ë¦¬</h4>\n<p>RAGì˜ ì‘ë™ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:</p>\n<ol>\n<li><strong>ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•œë‹¤</strong></li>\n<li><strong>RAGëŠ” ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ê²€ìƒ‰í•œë‹¤</strong></li>\n<li><strong>ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ë‹µë³€ì„ ìƒì„±í•œë‹¤</strong></li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># RAG ì‘ë™ ì›ë¦¬ ì˜ˆì‹œ</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">rag_process</span><span class=\"token punctuation\">(</span>user_query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># 1. ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥</span>\n    query <span class=\"token operator\">=</span> user_query\n\n    <span class=\"token comment\"># 2. ì™¸ë¶€ DBì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰</span>\n    relevant_docs <span class=\"token operator\">=</span> vector_db<span class=\"token punctuation\">.</span>search<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 3. ê²€ìƒ‰ëœ ì •ë³´ì™€ í•¨ê»˜ LLMì— ì „ë‹¬</span>\n    context <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>relevant_docs<span class=\"token punctuation\">)</span>\n    prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"Context: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>context<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\nQuestion: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>query<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\nAnswer:\"</span></span>\n\n    <span class=\"token comment\"># 4. ìµœì¢… ë‹µë³€ ìƒì„±</span>\n    answer <span class=\"token operator\">=</span> llm<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>prompt<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> answer</code></pre></div>\n<h2 id=\"2ï¸-ragëŠ”-ì™œ-í•„ìš”í• ê¹Œ\">2ï¸âƒ£ RAGëŠ” ì™œ í•„ìš”í• ê¹Œ?</h2>\n<h4 id=\"2-1-ëŒ€í˜•-ì–¸ì–´-ëª¨ë¸ì˜-í•œê³„\">2-1 ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ í•œê³„</h4>\n<p>ChatGPTì™€ ê°™ì€ <strong>ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸</strong>ë„ ë‹¤ìŒê³¼ ê°™ì€ í•œê³„ë¥¼ ê°€ì§„ë‹¤:</p>\n<ul>\n<li><strong>Knowledge Cutoff</strong>: í•™ìŠµ ì´í›„ì— ìƒˆë¡œ ë‚˜ì˜¨ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” ë‹µë³€ì´ ì–´ë ¤ì›€</li>\n<li><strong>Training Data Cutoff</strong>: í•™ìŠµí•˜ì§€ ì•Šì€ íŠ¹ì • ë„ë©”ì¸ ë°ì´í„°ë“¤ì— ëŒ€í•œ ì œí•œì  ì§€ì‹</li>\n<li><strong>í• ë£¨ì‹œë„¤ì´ì…˜</strong>: ì‚¬ì‹¤ì´ ì•„ë‹Œ ë‚´ìš©ì„ ê·¸ëŸ´ë“¯í•˜ê²Œ ìƒì„±í•˜ëŠ” ë¬¸ì œ</li>\n</ul>\n<h4 id=\"2-2-ragì˜-í•´ê²°-ë°©ì•ˆ\">2-2 RAGì˜ í•´ê²° ë°©ì•ˆ</h4>\n<p>RAGëŠ” <strong>ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶€ì¡±í•œ ë°ì´í„°ë¥¼ ì£¼ì…</strong>í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ ë°©ë²•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì´ì ì„ ì œê³µí•œë‹¤:</p>\n<ul>\n<li>ìµœì‹  ì •ë³´ì— ê¸°ë°˜í•œ ì •í™•í•œ ë‹µë³€ ìƒì„±</li>\n<li>íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì˜ ì‹¤ì‹œê°„ í™œìš©</li>\n<li>ì¶œì²˜ê°€ ëª…í™•í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µ ì œê³µ</li>\n</ul>\n<h2 id=\"3ï¸-rag-ì‘ë™-ê³¼ì •\">3ï¸âƒ£ RAG ì‘ë™ ê³¼ì •</h2>\n<h4 id=\"3-1-ë°ì´í„°-ì„ë² ë”©-ë°-vector-db-êµ¬ì¶•\">3-1 ë°ì´í„° ì„ë² ë”© ë° Vector DB êµ¬ì¶•</h4>\n<p>RAGì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” <strong>ë°ì´í„°ë¥¼ ì„ë² ë”© ëª¨ë¸ì— í†µí•©</strong>í•˜ëŠ” ê²ƒì´ë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ì„ë² ë”© ê³¼ì • ì˜ˆì‹œ</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_embeddings</span><span class=\"token punctuation\">(</span>text_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜\n    \"\"\"</span>\n    <span class=\"token comment\"># í…ìŠ¤íŠ¸ë¥¼ chunk ë‹¨ìœ„ë¡œ ë¶„í• </span>\n    chunks <span class=\"token operator\">=</span> chunk_text<span class=\"token punctuation\">(</span>text_data<span class=\"token punctuation\">,</span> chunk_size<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">,</span> chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># ê° chunkë¥¼ ë²¡í„°ë¡œ ë³€í™˜</span>\n    embeddings <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> chunk <span class=\"token keyword\">in</span> chunks<span class=\"token punctuation\">:</span>\n        embedding <span class=\"token operator\">=</span> embedding_model<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>chunk<span class=\"token punctuation\">)</span>\n        embeddings<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>embedding<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> chunks<span class=\"token punctuation\">,</span> embeddings</code></pre></div>\n<p><strong>ì„ë² ë”©</strong>ì´ë€ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë“±ì˜ ë°ì´í„°ë¥¼ <code class=\"language-text\">ë²¡í„° ì„ë² ë”©(Vector Embedding)</code>ë¼ê³  í•˜ëŠ” ìˆ˜ì¹˜í™”ëœ ë°°ì—´ë¡œ ë³€í™˜í•œ ë°©ë²•ì„ ì˜ë¯¸í•œë‹¤:</p>\n<ul>\n<li>ì‚¬ê³¼ = [0.00212, -0.00328, 0.00789...]</li>\n<li>ë°° = [0.00234, -0.00222, 0.00635...]</li>\n<li>ì»´í“¨í„° = [-0.078, 0.00986, 0.00123...]</li>\n</ul>\n<h3 id=\"chunkingì˜-ì´í•´\">Chunkingì˜ ì´í•´</h3>\n<p><strong>Chunking</strong>ì´ë€ ê¸´ ë¬¸ì„œë¥¼ AIì—ê²Œ í†µì§¸ë¡œ ì „ë‹¬í•˜ë©´ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ê±°ë‚˜ context ê¸¸ì´ ì œí•œì„ ì´ˆê³¼í•´ ì œëŒ€ë¡œ ì²˜ë¦¬í•˜ì§€ ëª»í•  ìˆ˜ ìˆì–´ì„œ, <strong>ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ë©ì–´ë¦¬ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…</strong>ì´ë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Chunking ì˜ˆì‹œ</span>\ndocument <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì¸ê³µì§€ëŠ¥ì— ê´€ì‹¬ì´ ë§ê³  ìƒì„±í˜• AIì— ëŒ€í•´ì„œ\nê³µë¶€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ RAGë¥¼ ë°°ì› ìŠµë‹ˆë‹¤.\"\"\"</span>\n\n<span class=\"token comment\"># Chunk ê²°ê³¼</span>\nchunks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì¸ê³µì§€ëŠ¥ì— ê´€ì‹¬ì´ ë§ê³  ìƒì„±í˜• AIì— ëŒ€í•´ì„œ ê³µë¶€í•˜\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"í˜• AIì— ëŒ€í•´ì„œ ê³µë¶€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ RAGë¥¼ ë°°ì› ìŠµë‹ˆë‹¤.\"</span>\n<span class=\"token punctuation\">]</span></code></pre></div>\n<p><strong>ì£¼ìš” íŒŒë¼ë¯¸í„°:</strong></p>\n<ul>\n<li><strong>chunk_size</strong>: í•˜ë‚˜ì˜ chunkì— í¬í•¨ë˜ëŠ” ê¸€ì ìˆ˜</li>\n<li><strong>chunk_overlap</strong>: ì²­í¬ë¼ë¦¬ ì¼ì • ë¶€ë¶„ ê²¹ì¹˜ê²Œ ë§Œë“œëŠ” ì„¤ì •</li>\n</ul>\n<p><code class=\"language-text\">chunk_overlap</code>ì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” chunkê°€ ì •í™•íˆ ì˜ë¦¬ëŠ” ì§€ì ì—ì„œ ë¬¸ì¥ì˜ ë§¥ë½ì´ ëŠê¸°ë©´ AIê°€ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ê¸° ì–´ë ¤ì›Œì§€ê¸° ë•Œë¬¸ì´ë‹¤.</p>\n<h4 id=\"3-2-ì¿¼ë¦¬-ë²¡í„°í™”-ë°-ê´€ë ¨-ì •ë³´-ì¶”ì¶œ\">3-2 ì¿¼ë¦¬ ë²¡í„°í™” ë° ê´€ë ¨ ì •ë³´ ì¶”ì¶œ</h4>\n<p>ì‚¬ìš©ìì˜ <strong>ì§ˆë¬¸ì„ ë²¡í„°í™”</strong>í•˜ê³ , <strong>ë²¡í„° DBë¥¼ ëŒ€ìƒìœ¼ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰</strong>ì„ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ìƒìœ„ Kê°œì˜ í•­ëª©ì„ ì¶”ì¶œí•œë‹¤.</p>\n<h5>ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰</h5>\n<p>ì„ë² ë”©ì„ í†µí•´ ì €ì¥ëœ ë°ì´í„°ëŠ” <strong>ë²¡í„° ê°„ì˜ ê±°ë¦¬ë¥¼ ì¸¡ì •</strong>í•˜ì—¬ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ í‰ê°€í•œë‹¤. ì£¼ìš” ìœ ì‚¬ë„ ì¸¡ì • ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:</p>\n<table>\n<thead>\n<tr>\n<th>ë°©ì‹</th>\n<th>ì„¤ëª…</th>\n<th>íŠ¹ì§•</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>ìœ í´ë¦¬ë“œ ê±°ë¦¬</strong></td>\n<td>ë‘ ë²¡í„°ì˜ ëì ì„ ì‡ëŠ” ê°€ì¥ ì§§ì€ ì§ì„ ê±°ë¦¬</td>\n<td>ë²¡í„°ì˜ í¬ê¸°ì™€ ë°©í–¥ì„ ëª¨ë‘ ê³ ë ¤</td>\n</tr>\n<tr>\n<td><strong>ì½”ì‚¬ì¸ ìœ ì‚¬ë„</strong></td>\n<td>ë‘ ë²¡í„°ê°„ì˜ ê°ë„ë¥¼ ì´ìš©í•˜ì—¬ ì¸¡ì •</td>\n<td>ë²¡í„°ì˜ ë°©í–¥ì— ì¤‘ì , ê³ ì°¨ì› ë°ì´í„°ì— íš¨ê³¼ì </td>\n</tr>\n<tr>\n<td><strong>ë‚´ì  ê¸°ë°˜ ìœ ì‚¬ë„</strong></td>\n<td>ë²¡í„°ì˜ ë‚´ì ìœ¼ë¡œ ì¸¡ì •</td>\n<td>ë°©í–¥ì„±ê³¼ í¬ê¸°ë¥¼ ëª¨ë‘ ê³ ë ¤</td>\n</tr>\n</tbody>\n</table>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">vector_similarity_search</span><span class=\"token punctuation\">(</span>query_vector<span class=\"token punctuation\">,</span> database_vectors<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    ì¿¼ë¦¬ ë²¡í„°ì™€ ê°€ì¥ ìœ ì‚¬í•œ ìƒìœ„ kê°œ ë²¡í„° ê²€ìƒ‰\n    \"\"\"</span>\n    similarities <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> doc_vector <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>database_vectors<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°</span>\n        similarity <span class=\"token operator\">=</span> cosine_similarity<span class=\"token punctuation\">(</span>query_vector<span class=\"token punctuation\">,</span> doc_vector<span class=\"token punctuation\">)</span>\n        similarities<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> similarity<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬ í›„ ìƒìœ„ kê°œ ë°˜í™˜</span>\n    similarities<span class=\"token punctuation\">.</span>sort<span class=\"token punctuation\">(</span>key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> reverse<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> similarities<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>top_k<span class=\"token punctuation\">]</span></code></pre></div>\n<h4 id=\"3-3-llmì„-í†µí•œ-ë‹µë³€-ìƒì„±\">3-3 LLMì„ í†µí•œ ë‹µë³€ ìƒì„±</h4>\n<p>LLMì€ <strong>ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì™€ ì¶”ì¶œëœ ê´€ë ¨ ì •ë³´</strong>ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•œë‹¤. ì´ ê³¼ì •ì—ì„œ <strong>ì •í™•í•œ ì¶œì²˜ì— ê¸°ë°˜í•œ ë‹µë³€</strong>ì´ ê°€ëŠ¥í•´ì§„ë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">generate_final_answer</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> retrieved_docs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±\n    \"\"\"</span>\n    <span class=\"token comment\"># ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©</span>\n    context <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>doc<span class=\"token punctuation\">.</span>content <span class=\"token keyword\">for</span> doc <span class=\"token keyword\">in</span> retrieved_docs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"\n    ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:\n\n    ë¬¸ì„œ ë‚´ìš©:\n    </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>context<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n\n    ì§ˆë¬¸: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>query<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n    ë‹µë³€:\n    \"\"\"</span></span>\n\n    response <span class=\"token operator\">=</span> llm<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>prompt<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> response</code></pre></div>\n<h2 id=\"4ï¸-rag-vs-fine-tuning\">4ï¸âƒ£ RAG vs Fine-tuning</h2>\n<p>ë‘ ê°€ì§€ ì ‘ê·¼ë²•ì˜ ì°¨ì´ì ì„ ëª…í™•íˆ ì´í•´í•´ë³´ì.</p>\n<h4 id=\"4-1-rag-ê²€ìƒ‰-ê¸°ë°˜-ìƒì„±\">4-1 RAG (ê²€ìƒ‰ ê¸°ë°˜ ìƒì„±)</h4>\n<p><strong>ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•´ GPTì—ê²Œ ì „ë‹¬</strong>í•˜ê³  ê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì´ë‹¤.</p>\n<h4 id=\"4-2-fine-tuning-ëª¨ë¸-ë¯¸ì„¸ì¡°ì •\">4-2 Fine-tuning (ëª¨ë¸ ë¯¸ì„¸ì¡°ì •)</h4>\n<p><strong>ê¸°ì¡´ GPT ëª¨ë¸ì— ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í•™ìŠµ</strong>ì‹œì¼œ, ëª¨ë¸ ìì²´ë¥¼ ë°”ê¾¸ëŠ” ë°©ì‹ì´ë‹¤.</p>\n<h4 id=\"4-3-ë¹„êµ-ë¶„ì„\">4-3 ë¹„êµ ë¶„ì„</h4>\n<table>\n<thead>\n<tr>\n<th>êµ¬ë¶„</th>\n<th>RAG</th>\n<th>Fine-tuning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>ë°ì´í„° ë°˜ì˜</strong></td>\n<td>ì™¸ë¶€ ë¬¸ì„œë§Œ ë°”ê¾¸ë©´ ì¦‰ì‹œ ë°˜ì˜</td>\n<td>ìƒˆë¡œ í•™ìŠµí•´ì•¼ ë°˜ì˜ë¨ (ëŠë¦¼)</td>\n</tr>\n<tr>\n<td><strong>êµ¬ì¶• ë³µì¡ë„</strong></td>\n<td>ë¬¸ì„œ ìª¼ê°œê¸° + ë²¡í„°DB êµ¬ì„±</td>\n<td>í•™ìŠµ ë°ì´í„° ì¤€ë¹„ + í•™ìŠµ + íŒŒë¼ë¯¸í„° ì¡°ì •</td>\n</tr>\n<tr>\n<td><strong>ë¹„ìš©</strong></td>\n<td>ìƒëŒ€ì ìœ¼ë¡œ ì €ë ´</td>\n<td>GPU ë¹„ìš© + í•™ìŠµì‹œê°„ + ëª¨ë¸ í˜¸ìŠ¤íŒ… ë¹„ìš©</td>\n</tr>\n<tr>\n<td><strong>ì‘ë‹µ ì†ë„</strong></td>\n<td>ê²€ìƒ‰ ë‹¨ê³„ë¡œ ì¸í•´ ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼</td>\n<td>ëª¨ë¸ ë‚´ì¥ ì§€ì‹ì´ë¼ ë¹ ë¦„</td>\n</tr>\n<tr>\n<td><strong>ìœ ì—°ì„±</strong></td>\n<td>ì‹¤ì‹œê°„ ì •ë³´ ì—…ë°ì´íŠ¸ ê°€ëŠ¥</td>\n<td>ëª¨ë¸ ì¬í•™ìŠµ í•„ìš”</td>\n</tr>\n</tbody>\n</table>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># RAG ë°©ì‹ ì˜ˆì‹œ</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">rag_approach</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    docs <span class=\"token operator\">=</span> vector_db<span class=\"token punctuation\">.</span>search<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># ì‹¤ì‹œê°„ ê²€ìƒ‰</span>\n    <span class=\"token keyword\">return</span> llm<span class=\"token punctuation\">.</span>generate_with_context<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> docs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Fine-tuning ë°©ì‹ ì˜ˆì‹œ</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">finetuned_approach</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> finetuned_model<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># í•™ìŠµëœ ì§€ì‹ í™œìš©</span></code></pre></div>\n<h2 id=\"5ï¸-vector-db\">5ï¸âƒ£ Vector DB</h2>\n<h4 id=\"5-1-vector-dbì˜-ì •ì˜\">5-1 Vector DBì˜ ì •ì˜</h4>\n<p><strong>Vector DB</strong>ëŠ” ë°ì´í„°ë¥¼ <strong>ë²¡í„° í˜•íƒœë¡œ ì €ì¥</strong>í•˜ê³ , <strong>ë²¡í„° ê°„ ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰</strong>í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‹¤.</p>\n<p>ê¸°ì¡´ì˜ ê´€ê³„í˜• DBê°€ í–‰ê³¼ ì—´ì˜ 2ì°¨ì› í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ í‘œí˜„í•˜ëŠ” ë°˜ë©´, Vector DBëŠ” <strong>ë‹¤ì°¨ì› ê³µê°„ìœ¼ë¡œ ê°œë…ì„ í™•ì¥</strong>í•œë‹¤.</p>\n<h4 id=\"5-2-vector-dbê°€-í•„ìš”í•œ-ì´ìœ \">5-2 Vector DBê°€ í•„ìš”í•œ ì´ìœ </h4>\n<p>ìƒì„±í˜• AIë‚˜ RAGì—ì„œ Vector DBë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ :</p>\n<ul>\n<li>ìì—°ì–´ ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì €ì¥í•˜ì§€ ì•ŠìŒ</li>\n<li><strong>AIê°€ ì´í•´ ê°€ëŠ¥í•œ í˜•íƒœì¸ ë²¡í„°ë¡œ ë³€í™˜</strong>í•˜ì—¬ ì €ì¥</li>\n<li><strong>ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ë¬¸ì„œë‚˜ ë¬¸ì¥ë“¤ì„ ë¹ ë¥´ê²Œ ê²€ìƒ‰</strong> ê°€ëŠ¥</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Vector DB ì €ì¥ ë° ê²€ìƒ‰ ì˜ˆì‹œ</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">SimpleVectorDB</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>vectors <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        self<span class=\"token punctuation\">.</span>documents <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">add_document</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">,</span> vector<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"ë¬¸ì„œì™€ ë²¡í„°ë¥¼ DBì— ì €ì¥\"\"\"</span>\n        self<span class=\"token punctuation\">.</span>documents<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>vectors<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>vector<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">search</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> query_vector<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"ì¿¼ë¦¬ ë²¡í„°ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰\"\"\"</span>\n        similarities <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> vec <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>vectors<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            sim <span class=\"token operator\">=</span> cosine_similarity<span class=\"token punctuation\">(</span>query_vector<span class=\"token punctuation\">,</span> vec<span class=\"token punctuation\">)</span>\n            similarities<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> sim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># ìƒìœ„ kê°œ ë°˜í™˜</span>\n        similarities<span class=\"token punctuation\">.</span>sort<span class=\"token punctuation\">(</span>key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> reverse<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        results <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> _ <span class=\"token keyword\">in</span> similarities<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>top_k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            results<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>documents<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> results</code></pre></div>\n<h4 id=\"5-3-ì£¼ìš”-vector-db-ì¢…ë¥˜\">5-3 ì£¼ìš” Vector DB ì¢…ë¥˜</h4>\n<table>\n<thead>\n<tr>\n<th>DB ì´ë¦„</th>\n<th>íŠ¹ì§•</th>\n<th>ì‚¬ìš© ì¼€ì´ìŠ¤</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Chroma</strong></td>\n<td>Python ê¸°ë°˜ ì˜¤í”ˆì†ŒìŠ¤, ì„¤ì¹˜ ê°„ë‹¨</td>\n<td>í”„ë¡œí† íƒ€ì…, ì‹¤ìŠµìš©</td>\n</tr>\n<tr>\n<td><strong>Pinecone</strong></td>\n<td>í´ë¼ìš°ë“œ ê¸°ë°˜, í™•ì¥ì„± ìš°ìˆ˜</td>\n<td>ìƒìš© ì„œë¹„ìŠ¤</td>\n</tr>\n<tr>\n<td><strong>Weaviate</strong></td>\n<td>GraphQL ì§€ì›, ë‹¤ì–‘í•œ ë²¡í„° ê²€ìƒ‰</td>\n<td>ë³µí•© ê²€ìƒ‰</td>\n</tr>\n<tr>\n<td><strong>Qdrant</strong></td>\n<td>Rust ê¸°ë°˜, ê³ ì„±ëŠ¥</td>\n<td>ëŒ€ìš©ëŸ‰ ì²˜ë¦¬</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"5-4-chroma-ì„ íƒ-ì´ìœ \">5-4 Chroma ì„ íƒ ì´ìœ </h4>\n<p>ì‹¤ìŠµì—ì„œ <strong>Chroma</strong>ë¥¼ ì„ íƒí•œ ì´ìœ :</p>\n<ul>\n<li>Python ê¸°ë°˜ì˜ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ <strong>ì„¤ì¹˜ ê³¼ì •ì´ ë‹¨ìˆœ</strong></li>\n<li>ë³„ë„ì˜ ì„œë²„ë¥¼ ë„ìš°ê±°ë‚˜ ë³µì¡í•œ ì„¤ì • ì—†ì´ <strong>ëª‡ ì¤„ì˜ ì½”ë“œë§Œìœ¼ë¡œ ë²¡í„° DB êµ¬ì¶• ê°€ëŠ¥</strong></li>\n<li>ë¹ ë¥´ê²Œ ê°œë…ì„ ìµíˆê³  ê°„ë‹¨í•œ í™˜ê²½ì—ì„œ ì§ì ‘ ì²´í—˜í•˜ê¸°ì— ì í•©</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># Chroma ì„¤ì¹˜</span>\npip <span class=\"token function\">install</span> chromadb</code></pre></div>\n<h2 id=\"6ï¸-ì‹¤ìŠµì½”ë“œ-1---vector-db-êµ¬ì¶•\">6ï¸âƒ£ ì‹¤ìŠµì½”ë“œ 1 - Vector DB êµ¬ì¶•</h2>\n<h4 id=\"6-1-ì „ì²´-íë¦„-ìš”ì•½\">6-1 ì „ì²´ íë¦„ ìš”ì•½</h4>\n<ul>\n<li><strong>ì´ˆê¸°í™”</strong>: ë°ì´í„°ë² ì´ìŠ¤ì™€ ì»¬ë ‰ì…˜ì„ ì´ˆê¸°í™”í•˜ì—¬ ì˜êµ¬ ì €ì¥ì†Œ ì¤€ë¹„</li>\n<li><strong>ë°ì´í„° ë¡œë“œ</strong>: ì§€ì •ëœ í´ë”ì—ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ë¶ˆëŸ¬ì˜´</li>\n<li><strong>ì „ì²˜ë¦¬</strong>: ê° í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì¼ì • ê¸¸ì´ì˜ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€</li>\n<li><strong>ì„ë² ë”© ìƒì„± ë° ì €ì¥</strong>: ê° ì²­í¬ì— ëŒ€í•´ OpenAI ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ë²¡í„° DBì— ì €ì¥</li>\n</ul>\n<h4 id=\"6-2-build_vector_dbpy-êµ¬í˜„\">6-2 build_vector_db.py êµ¬í˜„</h4>\n<h5>í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">from</span> openai <span class=\"token keyword\">import</span> OpenAI\n<span class=\"token keyword\">import</span> chromadb\n<span class=\"token keyword\">from</span> chromadb<span class=\"token punctuation\">.</span>config <span class=\"token keyword\">import</span> Settings\n<span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv\n\n<span class=\"token comment\"># í™˜ê²½ ë³€ìˆ˜ ë¡œë“œí•˜ì—¬ API í‚¤ ê°€ì ¸ì˜¤ê³  OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”</span>\nload_dotenv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\napi_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\nclient <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span></code></pre></div>\n<h5>DB ì´ˆê¸°í™” í•¨ìˆ˜</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">init_db</span><span class=\"token punctuation\">(</span>db_path<span class=\"token operator\">=</span><span class=\"token string\">\"./chroma_db\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Vector DB ì´ˆê¸°í™” ë° ì»¬ë ‰ì…˜ ìƒì„±\"\"\"</span>\n    dbclient <span class=\"token operator\">=</span> chromadb<span class=\"token punctuation\">.</span>PersistentClient<span class=\"token punctuation\">(</span>path<span class=\"token operator\">=</span>db_path<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># rag_collectionì´ë¼ëŠ” ë°ì´í„° ì»¬ë ‰ì…˜ ìƒì„±</span>\n    collection <span class=\"token operator\">=</span> dbclient<span class=\"token punctuation\">.</span>create_collection<span class=\"token punctuation\">(</span>\n        name<span class=\"token operator\">=</span><span class=\"token string\">\"rag_collection\"</span><span class=\"token punctuation\">,</span>\n        get_or_create<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> dbclient<span class=\"token punctuation\">,</span> collection</code></pre></div>\n<h5>í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”©</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">load_text_files</span><span class=\"token punctuation\">(</span>folder_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"ì§€ì •ëœ í´ë”ì—ì„œ ëª¨ë“  .txt íŒŒì¼ ë¡œë“œ\"\"\"</span>\n    docs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> filename <span class=\"token keyword\">in</span> os<span class=\"token punctuation\">.</span>listdir<span class=\"token punctuation\">(</span>folder_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        file_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>folder_path<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> file_path<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\".txt\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">\"r\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n                text <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                docs<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> docs</code></pre></div>\n<h5>ì„ë² ë”© ìƒì„±</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">get_embedding</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">,</span> model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜\"\"\"</span>\n    response <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>embeddings<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>text<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> model<span class=\"token operator\">=</span>model<span class=\"token punctuation\">)</span>\n    embedding <span class=\"token operator\">=</span> response<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding\n    <span class=\"token keyword\">return</span> embedding</code></pre></div>\n<h5>í…ìŠ¤íŠ¸ ì²­í‚¹</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">chunk_text</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">,</span> chunk_size<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">,</span> chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"ì›ì²œ ë°ì´í„°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³  overlap ì ìš©\"\"\"</span>\n    chunks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    start <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n    <span class=\"token keyword\">while</span> start <span class=\"token operator\">&lt;</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        end <span class=\"token operator\">=</span> start <span class=\"token operator\">+</span> chunk_size\n        chunk <span class=\"token operator\">=</span> text<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">:</span>end<span class=\"token punctuation\">]</span>\n        chunks<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>chunk<span class=\"token punctuation\">)</span>\n        start <span class=\"token operator\">=</span> end <span class=\"token operator\">-</span> chunk_overlap\n\n        <span class=\"token comment\"># ì˜ˆì™¸ ì²˜ë¦¬</span>\n        <span class=\"token keyword\">if</span> start <span class=\"token operator\">&lt;</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            start <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n        <span class=\"token keyword\">if</span> start <span class=\"token operator\">>=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">break</span>\n\n    <span class=\"token keyword\">return</span> chunks</code></pre></div>\n<h5>ë©”ì¸ ì‹¤í–‰ ë¡œì§</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># DB ì´ˆê¸°í™”</span>\n    dbclient<span class=\"token punctuation\">,</span> collection <span class=\"token operator\">=</span> init_db<span class=\"token punctuation\">(</span><span class=\"token string\">\"./chroma_db\"</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># ë¬¸ì„œ ë¡œë“œ</span>\n    folder_path <span class=\"token operator\">=</span> <span class=\"token string\">\"./source_data\"</span>\n    docs <span class=\"token operator\">=</span> load_text_files<span class=\"token punctuation\">(</span>folder_path<span class=\"token punctuation\">)</span>\n\n    doc_id <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> filename<span class=\"token punctuation\">,</span> text <span class=\"token keyword\">in</span> docs<span class=\"token punctuation\">:</span>\n        chunks <span class=\"token operator\">=</span> chunk_text<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">,</span> chunk_size<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">,</span> chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> chunk <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>chunks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            doc_id <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            embedding <span class=\"token operator\">=</span> get_embedding<span class=\"token punctuation\">(</span>chunk<span class=\"token punctuation\">)</span>\n\n            <span class=\"token comment\"># Vector DBì— ì €ì¥</span>\n            collection<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>\n                documents<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>chunk<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># ì‹¤ì œ ì²­í¬ í…ìŠ¤íŠ¸</span>\n                embeddings<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>embedding<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># ìƒì„±ëœ ì„ë² ë”© ë²¡í„°</span>\n                metadatas<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n                    <span class=\"token string\">\"filename\"</span><span class=\"token punctuation\">:</span> filename<span class=\"token punctuation\">,</span>\n                    <span class=\"token string\">\"chunk_index\"</span><span class=\"token punctuation\">:</span> idx\n                <span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                ids<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>doc_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># ê³ ìœ  ì‹ë³„ì</span>\n            <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ëª¨ë“  ë¬¸ì„œê°€ Vector DBì— ì €ì¥ ì™„ë£Œ\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"7ï¸-ì‹¤ìŠµì½”ë“œ-2---rag-ì±—ë´‡-êµ¬í˜„\">7ï¸âƒ£ ì‹¤ìŠµì½”ë“œ 2 - RAG ì±—ë´‡ êµ¬í˜„</h2>\n<h4 id=\"7-1-rag_chatbotpy-êµ¬í˜„\">7-1 rag_chatbot.py êµ¬í˜„</h4>\n<h5>í™˜ê²½ ì„¤ì • ë° DB ì—°ê²°</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">from</span> openai <span class=\"token keyword\">import</span> OpenAI\n<span class=\"token keyword\">from</span> build_vector_db <span class=\"token keyword\">import</span> get_embedding\n<span class=\"token keyword\">import</span> chromadb\n<span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv\n\nload_dotenv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndbclient <span class=\"token operator\">=</span> chromadb<span class=\"token punctuation\">.</span>PersistentClient<span class=\"token punctuation\">(</span>path<span class=\"token operator\">=</span><span class=\"token string\">\"./chroma_db\"</span><span class=\"token punctuation\">)</span>\ncollection <span class=\"token operator\">=</span> dbclient<span class=\"token punctuation\">.</span>get_or_create_collection<span class=\"token punctuation\">(</span><span class=\"token string\">\"rag_collection\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h5>ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">retrieve</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"ì¿¼ë¦¬ë¥¼ ì„ë² ë”©í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ top-kê°œ ë¬¸ì„œ ê²€ìƒ‰\"\"\"</span>\n    query_embedding <span class=\"token operator\">=</span> get_embedding<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Vector DBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰</span>\n    results <span class=\"token operator\">=</span> collection<span class=\"token punctuation\">.</span>query<span class=\"token punctuation\">(</span>\n        query_embeddings<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>query_embedding<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        n_results<span class=\"token operator\">=</span>top_k\n    <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> results</code></pre></div>\n<h5>RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">generate_answer_with_context</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    RAG ê¸°ë°˜ ë‹µë³€ ìƒì„± í”„ë¡œì„¸ìŠ¤:\n    1) ì¿¼ë¦¬ì— ëŒ€í•´ Vector DBì—ì„œ top_kê°œ ë¬¸ì„œ ê²€ìƒ‰\n    2) ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ contextë¡œ êµ¬ì„±\n    3) Contextì™€ í•¨ê»˜ GPTì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬\n    4) ìµœì¢… ë‹µë³€ ë°˜í™˜\n    \"\"\"</span>\n\n    <span class=\"token comment\"># 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰</span>\n    results <span class=\"token operator\">=</span> retrieve<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token punctuation\">)</span>\n    found_docs <span class=\"token operator\">=</span> results<span class=\"token punctuation\">[</span><span class=\"token string\">\"documents\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    found_metadatas <span class=\"token operator\">=</span> results<span class=\"token punctuation\">[</span><span class=\"token string\">\"metadatas\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\"># 2. Context êµ¬ì„±</span>\n    context_texts <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> doc_text<span class=\"token punctuation\">,</span> meta <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>found_docs<span class=\"token punctuation\">,</span> found_metadatas<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        context_texts<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>\n            <span class=\"token string-interpolation\"><span class=\"token string\">f\"&lt;&lt;filename: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>meta<span class=\"token punctuation\">[</span><span class=\"token string\">'filename'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">>>\\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>doc_text<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span>\n        <span class=\"token punctuation\">)</span>\n    context_str <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>context_texts<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 3. í”„ë¡¬í”„íŠ¸ ì‘ì„±</span>\n    system_prompt <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"\n    ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”\n    ì§€ëŠ¥í˜• ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì›ì¹™ì„ ì—„ê²©íˆ ì§€í‚¤ì„¸ìš”:\n\n    1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•´ì„œë§Œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.\n    2. ë¬¸ì„œì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ë‚´ìš©ì´ë¼ë©´, í•¨ë¶€ë¡œ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.\n    3. ì‚¬ì‹¤ ê´€ê³„ë¥¼ ëª…í™•íˆ ê¸°ìˆ í•˜ê³ , ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ \"ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤\"ë¼ê³  ë§í•˜ì„¸ìš”.\n    4. ì§€ë‚˜ì¹˜ê²Œ ì¥í™©í•˜ì§€ ì•Šê²Œ, ê°„ê²°í•˜ê³  ì•Œê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.\n    5. ë¬¸ì„œ ì¶œì²˜ë‚˜ ì—°ë„ê°€ ì¤‘ìš”í•˜ë‹¤ë©´, ê°€ëŠ¥í•œ ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”.\n    \"\"\"</span>\n\n    user_prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"ì•„ë˜ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì…ë‹ˆë‹¤:\n    </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>context_str<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n    ì§ˆë¬¸: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>query<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"\"\"</span></span>\n\n    <span class=\"token comment\"># 4. ChatGPT í˜¸ì¶œ</span>\n    api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\n    client <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span>\n\n    response <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">.</span>completions<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n        model<span class=\"token operator\">=</span><span class=\"token string\">\"gpt-4o-mini\"</span><span class=\"token punctuation\">,</span>\n        messages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"system\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> system_prompt<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> user_prompt<span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n\n    answer <span class=\"token operator\">=</span> response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>message<span class=\"token punctuation\">.</span>content\n    <span class=\"token keyword\">return</span> answer</code></pre></div>\n<h5>ë¹„êµìš© ì¼ë°˜ GPT ë‹µë³€</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">generate_answer_without_context</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"RAG ì—†ì´ ì¼ë°˜ GPTë¡œ ë‹µë³€í•˜ëŠ” í•¨ìˆ˜\"\"\"</span>\n    api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\n    client <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span>\n\n    response <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">.</span>completions<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n        model<span class=\"token operator\">=</span><span class=\"token string\">\"gpt-4o-mini\"</span><span class=\"token punctuation\">,</span>\n        messages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"system\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"You are a helpful assistant\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> query<span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n\n    answer <span class=\"token operator\">=</span> response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>message<span class=\"token punctuation\">.</span>content\n    <span class=\"token keyword\">return</span> answer</code></pre></div>\n<h5>ë©”ì¸ ì‹¤í–‰ ë£¨í”„</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        user_query <span class=\"token operator\">=</span> <span class=\"token builtin\">input</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”(ì¢…ë£Œ: quit): \"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> user_query<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"quit\"</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">break</span>\n\n        <span class=\"token comment\"># RAG ê¸°ë°˜ ë‹µë³€</span>\n        answer <span class=\"token operator\">=</span> generate_answer_with_context<span class=\"token punctuation\">(</span>user_query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># ì¼ë°˜ GPT ë‹µë³€ (ë¹„êµìš©)</span>\n        <span class=\"token comment\"># answer = generate_answer_without_context(user_query)</span>\n\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"===ë‹µë³€===\"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>answer<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"==========\\n\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h4 id=\"7-2-ê²€ìƒ‰-ê²°ê³¼-ë°ì´í„°-êµ¬ì¡°\">7-2 ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° êµ¬ì¡°</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># collection.query() ê²°ê³¼ ì˜ˆì‹œ</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token string\">\"documents\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">[</span>ë¬¸ì„œ<span class=\"token number\">1</span><span class=\"token punctuation\">,</span> ë¬¸ì„œ<span class=\"token number\">2</span><span class=\"token punctuation\">,</span> ë¬¸ì„œ<span class=\"token number\">3</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># í•œ ê°œì˜ ì¿¼ë¦¬ì— ëŒ€í•œ top_k ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸</span>\n  <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string\">\"metadatas\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">[</span>ë©”íƒ€ë°ì´í„°<span class=\"token number\">1</span><span class=\"token punctuation\">,</span> ë©”íƒ€ë°ì´í„°<span class=\"token number\">2</span><span class=\"token punctuation\">,</span> ë©”íƒ€ë°ì´í„°<span class=\"token number\">3</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># ê° ë¬¸ì„œì— í•´ë‹¹í•˜ëŠ” ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"-ì •ë¦¬\">âœ… ì •ë¦¬</h2>\n<p><strong>RAGì˜ í•µì‹¬ í¬ì¸íŠ¸</strong></p>\n<ul>\n<li>ğŸ” <strong>ê²€ìƒ‰ ê¸°ë°˜</strong>: ì™¸ë¶€ ì§€ì‹ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ í™œìš©</li>\n<li>ğŸ“Š <strong>ë²¡í„° ê²€ìƒ‰</strong>: ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ì˜ ì •í™•í•œ ë¬¸ì„œ ê²€ìƒ‰</li>\n<li>ğŸ¯ <strong>ë§¥ë½ ì œê³µ</strong>: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë§¥ë½ìœ¼ë¡œ í™œìš©í•œ ì •í™•í•œ ë‹µë³€ ìƒì„±</li>\n<li>âš¡ <strong>ì‹¤ì‹œê°„ ë°˜ì˜</strong>: ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥</li>\n</ul>\n<p><strong>RAG vs Fine-tuning ì„ íƒ ê¸°ì¤€</strong></p>\n<ul>\n<li><strong>RAG</strong>: ì‹¤ì‹œê°„ ì •ë³´ ì—…ë°ì´íŠ¸, ë¹„ìš© íš¨ìœ¨ì„±, ì¶œì²˜ ëª…ì‹œê°€ ì¤‘ìš”í•œ ê²½ìš°</li>\n<li><strong>Fine-tuning</strong>: íŠ¹ì • ìŠ¤íƒ€ì¼/í†¤ í•™ìŠµ, ì‘ë‹µ ì†ë„, ì¼ê´€ëœ í–‰ë™ íŒ¨í„´ì´ ì¤‘ìš”í•œ ê²½ìš°</li>\n</ul>\n<p><strong>êµ¬í˜„ ì‹œ ê³ ë ¤ì‚¬í•­</strong></p>\n<ul>\n<li><strong>ì²­í‚¹ ì „ëµ</strong>: chunk_sizeì™€ overlap ìµœì í™”</li>\n<li><strong>ë²¡í„° DB ì„ íƒ</strong>: ìš©ëŸ‰ê³¼ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” DB ì„ íƒ</li>\n<li><strong>ì„ë² ë”© ëª¨ë¸</strong>: ë„ë©”ì¸ì— íŠ¹í™”ëœ ì„ë² ë”© ëª¨ë¸ í™œìš©</li>\n<li><strong>ê²€ìƒ‰ ìµœì í™”</strong>: ìœ ì‚¬ë„ ê¸°ì¤€ê³¼ ìƒìœ„ Kê°œ ê²°ê³¼ ìˆ˜ ì¡°ì •</li>\n</ul>\n<p>RAGëŠ” í˜„ì¬ ìƒì„±í˜• AIì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ì„œë¹„ìŠ¤ë¥¼ êµ¬ì¶•í•˜ëŠ” í•µì‹¬ ê¸°ìˆ ì´ë‹¤. ì²´ê³„ì ì¸ ì´í•´ì™€ ì‹¤ìŠµì„ í†µí•´ ì‹¤ë¬´ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë‹¤.</p>","fields":{"slug":"/rag-core-concept/"},"frontmatter":{"title":"RAGì˜ í•µì‹¬ ê°œë…ê³¼ ì‹¤ìŠµ","date":"2025-10-01","description":"RAGì˜ í•µì‹¬ ê°œë…ë¶€í„° ë²¡í„° DB êµ¬ì¶•, ì‹¤ì œ ì±—ë´‡ êµ¬í˜„ê¹Œì§€ Python ì½”ë“œì™€ í•¨ê»˜ ì•Œì•„ë³´ì.","pointColor":"#FF6B6B","tags":["AI"],"keywords":"RAG, ê²€ìƒ‰ ì¦ê°• ìƒì„±, Retrieval-Augmented Generation, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤, Vector DB, LLM, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸, ì±—ë´‡, AI, ë¨¸ì‹ ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬, NLP, Python, ì„ë² ë”©, Embedding","thumbnail":{"publicURL":"/static/c4d3f090e61c211003c9351ae4baa2f3/index.png","childImageSharp":{"gatsbyImageData":{"layout":"fixed","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACLElEQVR42pWT30/TUBTH9zf6qC8mJsZHHo2E+ONJH+TBBB8w0RhFIhIVEiCLZkiYgMCWzf2irGzrtq4dGdtKXbt16z7edqtCooInOWlu7/l+7/d+z7khLojhcEij4/h5mQgFIC86lkW5UqNa1UVq6McNiorKu40ECyK1Wh1V1alUNKriWy6rWJZ9ntCjcl3XXxiGSSotkc4ckspIVJUypbzMQVbiSC6SO5DJ5vIkUwf+vldrmh0f63EMA4XuWKVpmvT7/V+nJZtdto9tHFHcE+rP7nnhOI6P8bCDQKFuu3xYXWJha5+pLZVXaY0fzoCVQpNrKxI3wjIzMRWtecqXvMazbXEDvU27N2BO1HqYN1/3WV77iCZuH9o5drj7+iXX364zGWvxKF5nQz3l3k6VyWiJx7Eatz4XiNZt5hMKq8kjFlMqEdVkOqEz8a3B1fl1n2O30R95GCupFBoGUXGE1O760nXR1dubCjc/yaRPrJHH3T75eotOf+T5YatLVLcpCvV7gmMYNOVsDIRfpmEQ1wzKZo+2INmqGrRbbXrOaHT8Rg7/MTauMHWUwuiBS010NyzXkY0ehuOyJJ+glBQsuzuezRHYqx+Mce74Z+jP0+yiGhZ7SoOcVCJZ0M8RXTjYv1/F2Bv1OwszUzx4+p7ni6s8fLGM1LIJbnNpwmDAw+kITyausDY7TXhjmTuzc9yPZP+fMHiCklYhvbuJlM1wWC6SyeeJy6W/NuIs4U8ZiMyIXp+s4wAAAABJRU5ErkJggg=="},"backgroundColor":"transparent","images":{"fallback":{"src":"/static/c4d3f090e61c211003c9351ae4baa2f3/1b037/index.png","srcSet":"/static/c4d3f090e61c211003c9351ae4baa2f3/1b037/index.png 568w","sizes":"568px"},"sources":[{"srcSet":"/static/c4d3f090e61c211003c9351ae4baa2f3/db111/index.webp 568w","type":"image/webp","sizes":"568px"}]},"width":1200,"height":799},"fixed":{"src":"/static/c4d3f090e61c211003c9351ae4baa2f3/0030e/index.png"}}}}},"previous":{"fields":{"slug":"/prompt-engineering-basic/"},"frontmatter":{"title":"í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ - AIì™€ íš¨ê³¼ì ìœ¼ë¡œ ì†Œí†µí•˜ëŠ” ë°©ë²•"}},"next":{"fields":{"slug":"/make-huggingface-pipeline/"},"frontmatter":{"title":"í—ˆê¹…í˜ì´ìŠ¤ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ì–´ë³´ì - íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ í™œìš© ê°€ì´ë“œ"}}},"pageContext":{"id":"464044b0-2b70-5b20-aa99-3adf6538535c","previousPostId":"d2564ce0-b7e9-5fd0-a411-b9adc95ed245","nextPostId":"feda185b-3dec-5ec6-b024-fa2b1b21b98a"}},"staticQueryHashes":["736397157"],"slicesMap":{}}