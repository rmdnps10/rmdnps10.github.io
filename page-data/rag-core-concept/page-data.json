{"componentChunkName":"component---src-templates-blog-post-js","path":"/rag-core-concept/","result":{"data":{"site":{"siteMetadata":{"title":"메인","siteUrl":"https://inyoung.dev","author":{"name":"Inyoung Chung"}}},"markdownRemark":{"id":"4490516c-c3e3-53b6-9172-49cc2438814e","excerpt":"대형 언어 모델의 한계를 극복하고 실시간 정보 활용을 가능하게 하는 RAG 기술이 주목받고 있다. 검색과 생성을 결합한 이 혁신적인 접근법을 이론부터 실습까지 알아보자. 1️⃣ RAG란? 1-1 RAG…","html":"<blockquote>\n<p>대형 언어 모델의 한계를 극복하고 실시간 정보 활용을 가능하게 하는 RAG 기술이 주목받고 있다. 검색과 생성을 결합한 이 혁신적인 접근법을 이론부터 실습까지 알아보자.</p>\n</blockquote>\n<h2 id=\"1️-rag란\">1️⃣ RAG란?</h2>\n<h4 id=\"1-1-rag의-정의\">1-1 RAG의 정의</h4>\n<p><code class=\"language-text\">RAG(Retrieval-Augmented Generation)</code>는 자연어 처리 분야에서 사용되는 기술로 <strong>정보 검색을 통해</strong> 언어 생성 과정을 향상시키는 방식이다.</p>\n<p>기존 언어 모델이 사전 학습된 지식에만 의존하는 반면, RAG는 외부 데이터베이스에서 관련 정보를 실시간으로 검색하여 더 정확하고 최신의 답변을 생성한다.</p>\n<h4 id=\"1-2-rag-작동-원리\">1-2 RAG 작동 원리</h4>\n<p>RAG의 작동 과정은 다음과 같다:</p>\n<ol>\n<li><strong>사용자가 질문을 입력한다</strong></li>\n<li><strong>RAG는 외부 데이터베이스에서 질문과 관련된 정보를 검색한다</strong></li>\n<li><strong>검색된 정보를 기반으로 LLM이 답변을 생성한다</strong></li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># RAG 작동 원리 예시</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">rag_process</span><span class=\"token punctuation\">(</span>user_query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># 1. 사용자 질문 입력</span>\n    query <span class=\"token operator\">=</span> user_query\n\n    <span class=\"token comment\"># 2. 외부 DB에서 관련 정보 검색</span>\n    relevant_docs <span class=\"token operator\">=</span> vector_db<span class=\"token punctuation\">.</span>search<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 3. 검색된 정보와 함께 LLM에 전달</span>\n    context <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>relevant_docs<span class=\"token punctuation\">)</span>\n    prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"Context: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>context<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\nQuestion: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>query<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\nAnswer:\"</span></span>\n\n    <span class=\"token comment\"># 4. 최종 답변 생성</span>\n    answer <span class=\"token operator\">=</span> llm<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>prompt<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> answer</code></pre></div>\n<h2 id=\"2️-rag는-왜-필요할까\">2️⃣ RAG는 왜 필요할까?</h2>\n<h4 id=\"2-1-대형-언어-모델의-한계\">2-1 대형 언어 모델의 한계</h4>\n<p>ChatGPT와 같은 <strong>대량의 데이터를 학습한 대규모 언어 모델</strong>도 다음과 같은 한계를 가진다:</p>\n<ul>\n<li><strong>Knowledge Cutoff</strong>: 학습 이후에 새로 나온 데이터에 대해서는 답변이 어려움</li>\n<li><strong>Training Data Cutoff</strong>: 학습하지 않은 특정 도메인 데이터들에 대한 제한적 지식</li>\n<li><strong>할루시네이션</strong>: 사실이 아닌 내용을 그럴듯하게 생성하는 문제</li>\n</ul>\n<h4 id=\"2-2-rag의-해결-방안\">2-2 RAG의 해결 방안</h4>\n<p>RAG는 <strong>실시간으로 부족한 데이터를 주입</strong>하기 위해 고안된 방법으로 다음과 같은 이점을 제공한다:</p>\n<ul>\n<li>최신 정보에 기반한 정확한 답변 생성</li>\n<li>특정 도메인 지식의 실시간 활용</li>\n<li>출처가 명확한 신뢰할 수 있는 응답 제공</li>\n</ul>\n<h2 id=\"3️-rag-작동-과정\">3️⃣ RAG 작동 과정</h2>\n<h4 id=\"3-1-데이터-임베딩-및-vector-db-구축\">3-1 데이터 임베딩 및 Vector DB 구축</h4>\n<p>RAG의 첫 번째 단계는 <strong>데이터를 임베딩 모델에 통합</strong>하는 것이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 임베딩 과정 예시</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_embeddings</span><span class=\"token punctuation\">(</span>text_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    텍스트 데이터를 임베딩 벡터로 변환\n    \"\"\"</span>\n    <span class=\"token comment\"># 텍스트를 chunk 단위로 분할</span>\n    chunks <span class=\"token operator\">=</span> chunk_text<span class=\"token punctuation\">(</span>text_data<span class=\"token punctuation\">,</span> chunk_size<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">,</span> chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 각 chunk를 벡터로 변환</span>\n    embeddings <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> chunk <span class=\"token keyword\">in</span> chunks<span class=\"token punctuation\">:</span>\n        embedding <span class=\"token operator\">=</span> embedding_model<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>chunk<span class=\"token punctuation\">)</span>\n        embeddings<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>embedding<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> chunks<span class=\"token punctuation\">,</span> embeddings</code></pre></div>\n<p><strong>임베딩</strong>이란 텍스트, 이미지 등의 데이터를 <code class=\"language-text\">벡터 임베딩(Vector Embedding)</code>라고 하는 수치화된 배열로 변환한 방법을 의미한다:</p>\n<ul>\n<li>사과 = [0.00212, -0.00328, 0.00789...]</li>\n<li>배 = [0.00234, -0.00222, 0.00635...]</li>\n<li>컴퓨터 = [-0.078, 0.00986, 0.00123...]</li>\n</ul>\n<h3 id=\"chunking의-이해\">Chunking의 이해</h3>\n<p><strong>Chunking</strong>이란 긴 문서를 AI에게 통째로 전달하면 성능이 떨어지거나 context 길이 제한을 초과해 제대로 처리하지 못할 수 있어서, <strong>긴 문서를 작은 덩어리로 나누는 작업</strong>이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Chunking 예시</span>\ndocument <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"안녕하세요. 저는 인공지능에 관심이 많고 생성형 AI에 대해서\n공부하고 있습니다. 오늘은 RAG를 배웠습니다.\"\"\"</span>\n\n<span class=\"token comment\"># Chunk 결과</span>\nchunks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"안녕하세요. 저는 인공지능에 관심이 많고 생성형 AI에 대해서 공부하\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"형 AI에 대해서 공부하고 있습니다. 오늘은 RAG를 배웠습니다.\"</span>\n<span class=\"token punctuation\">]</span></code></pre></div>\n<p><strong>주요 파라미터:</strong></p>\n<ul>\n<li><strong>chunk_size</strong>: 하나의 chunk에 포함되는 글자 수</li>\n<li><strong>chunk_overlap</strong>: 청크끼리 일정 부분 겹치게 만드는 설정</li>\n</ul>\n<p><code class=\"language-text\">chunk_overlap</code>을 사용하는 이유는 chunk가 정확히 잘리는 지점에서 문장의 맥락이 끊기면 AI가 의미를 파악하기 어려워지기 때문이다.</p>\n<h4 id=\"3-2-쿼리-벡터화-및-관련-정보-추출\">3-2 쿼리 벡터화 및 관련 정보 추출</h4>\n<p>사용자의 <strong>질문을 벡터화</strong>하고, <strong>벡터 DB를 대상으로 유사도 검색</strong>을 사용하여 가장 관련성이 높은 상위 K개의 항목을 추출한다.</p>\n<h5>벡터 유사도 검색</h5>\n<p>임베딩을 통해 저장된 데이터는 <strong>벡터 간의 거리를 측정</strong>하여 얼마나 유사한지를 평가한다. 주요 유사도 측정 방식은 다음과 같다:</p>\n<table>\n<thead>\n<tr>\n<th>방식</th>\n<th>설명</th>\n<th>특징</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>유클리드 거리</strong></td>\n<td>두 벡터의 끝점을 잇는 가장 짧은 직선거리</td>\n<td>벡터의 크기와 방향을 모두 고려</td>\n</tr>\n<tr>\n<td><strong>코사인 유사도</strong></td>\n<td>두 벡터간의 각도를 이용하여 측정</td>\n<td>벡터의 방향에 중점, 고차원 데이터에 효과적</td>\n</tr>\n<tr>\n<td><strong>내적 기반 유사도</strong></td>\n<td>벡터의 내적으로 측정</td>\n<td>방향성과 크기를 모두 고려</td>\n</tr>\n</tbody>\n</table>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">vector_similarity_search</span><span class=\"token punctuation\">(</span>query_vector<span class=\"token punctuation\">,</span> database_vectors<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    쿼리 벡터와 가장 유사한 상위 k개 벡터 검색\n    \"\"\"</span>\n    similarities <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> doc_vector <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>database_vectors<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># 코사인 유사도 계산</span>\n        similarity <span class=\"token operator\">=</span> cosine_similarity<span class=\"token punctuation\">(</span>query_vector<span class=\"token punctuation\">,</span> doc_vector<span class=\"token punctuation\">)</span>\n        similarities<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> similarity<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 유사도 기준 정렬 후 상위 k개 반환</span>\n    similarities<span class=\"token punctuation\">.</span>sort<span class=\"token punctuation\">(</span>key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> reverse<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> similarities<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>top_k<span class=\"token punctuation\">]</span></code></pre></div>\n<h4 id=\"3-3-llm을-통한-답변-생성\">3-3 LLM을 통한 답변 생성</h4>\n<p>LLM은 <strong>쿼리 텍스트와 추출된 관련 정보</strong>를 바탕으로 최종 답변을 생성한다. 이 과정에서 <strong>정확한 출처에 기반한 답변</strong>이 가능해진다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">generate_final_answer</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> retrieved_docs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    검색된 문서를 바탕으로 최종 답변 생성\n    \"\"\"</span>\n    <span class=\"token comment\"># 검색된 문서들을 하나의 컨텍스트로 결합</span>\n    context <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>doc<span class=\"token punctuation\">.</span>content <span class=\"token keyword\">for</span> doc <span class=\"token keyword\">in</span> retrieved_docs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"\n    다음 문서들을 참고하여 질문에 답변해주세요:\n\n    문서 내용:\n    </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>context<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n\n    질문: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>query<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n    답변:\n    \"\"\"</span></span>\n\n    response <span class=\"token operator\">=</span> llm<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>prompt<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> response</code></pre></div>\n<h2 id=\"4️-rag-vs-fine-tuning\">4️⃣ RAG vs Fine-tuning</h2>\n<p>두 가지 접근법의 차이점을 명확히 이해해보자.</p>\n<h4 id=\"4-1-rag-검색-기반-생성\">4-1 RAG (검색 기반 생성)</h4>\n<p><strong>외부 지식을 검색해 GPT에게 전달</strong>하고 그를 바탕으로 응답을 생성하는 방식이다.</p>\n<h4 id=\"4-2-fine-tuning-모델-미세조정\">4-2 Fine-tuning (모델 미세조정)</h4>\n<p><strong>기존 GPT 모델에 새로운 데이터를 학습</strong>시켜, 모델 자체를 바꾸는 방식이다.</p>\n<h4 id=\"4-3-비교-분석\">4-3 비교 분석</h4>\n<table>\n<thead>\n<tr>\n<th>구분</th>\n<th>RAG</th>\n<th>Fine-tuning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>데이터 반영</strong></td>\n<td>외부 문서만 바꾸면 즉시 반영</td>\n<td>새로 학습해야 반영됨 (느림)</td>\n</tr>\n<tr>\n<td><strong>구축 복잡도</strong></td>\n<td>문서 쪼개기 + 벡터DB 구성</td>\n<td>학습 데이터 준비 + 학습 + 파라미터 조정</td>\n</tr>\n<tr>\n<td><strong>비용</strong></td>\n<td>상대적으로 저렴</td>\n<td>GPU 비용 + 학습시간 + 모델 호스팅 비용</td>\n</tr>\n<tr>\n<td><strong>응답 속도</strong></td>\n<td>검색 단계로 인해 상대적으로 느림</td>\n<td>모델 내장 지식이라 빠름</td>\n</tr>\n<tr>\n<td><strong>유연성</strong></td>\n<td>실시간 정보 업데이트 가능</td>\n<td>모델 재학습 필요</td>\n</tr>\n</tbody>\n</table>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># RAG 방식 예시</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">rag_approach</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    docs <span class=\"token operator\">=</span> vector_db<span class=\"token punctuation\">.</span>search<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 실시간 검색</span>\n    <span class=\"token keyword\">return</span> llm<span class=\"token punctuation\">.</span>generate_with_context<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> docs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Fine-tuning 방식 예시</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">finetuned_approach</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> finetuned_model<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 학습된 지식 활용</span></code></pre></div>\n<h2 id=\"5️-vector-db\">5️⃣ Vector DB</h2>\n<h4 id=\"5-1-vector-db의-정의\">5-1 Vector DB의 정의</h4>\n<p><strong>Vector DB</strong>는 데이터를 <strong>벡터 형태로 저장</strong>하고, <strong>벡터 간 유사도를 기반으로 검색</strong>하는 데이터베이스다.</p>\n<p>기존의 관계형 DB가 행과 열의 2차원 형식으로 데이터를 표현하는 반면, Vector DB는 <strong>다차원 공간으로 개념을 확장</strong>한다.</p>\n<h4 id=\"5-2-vector-db가-필요한-이유\">5-2 Vector DB가 필요한 이유</h4>\n<p>생성형 AI나 RAG에서 Vector DB를 사용하는 이유:</p>\n<ul>\n<li>자연어 문서를 텍스트 그대로 저장하지 않음</li>\n<li><strong>AI가 이해 가능한 형태인 벡터로 변환</strong>하여 저장</li>\n<li><strong>유사한 의미의 문서나 문장들을 빠르게 검색</strong> 가능</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Vector DB 저장 및 검색 예시</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">SimpleVectorDB</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>vectors <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        self<span class=\"token punctuation\">.</span>documents <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">add_document</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">,</span> vector<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"문서와 벡터를 DB에 저장\"\"\"</span>\n        self<span class=\"token punctuation\">.</span>documents<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>vectors<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>vector<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">search</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> query_vector<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"쿼리 벡터와 유사한 문서 검색\"\"\"</span>\n        similarities <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> vec <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>vectors<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            sim <span class=\"token operator\">=</span> cosine_similarity<span class=\"token punctuation\">(</span>query_vector<span class=\"token punctuation\">,</span> vec<span class=\"token punctuation\">)</span>\n            similarities<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> sim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># 상위 k개 반환</span>\n        similarities<span class=\"token punctuation\">.</span>sort<span class=\"token punctuation\">(</span>key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> reverse<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        results <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> _ <span class=\"token keyword\">in</span> similarities<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>top_k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            results<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>documents<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> results</code></pre></div>\n<h4 id=\"5-3-주요-vector-db-종류\">5-3 주요 Vector DB 종류</h4>\n<table>\n<thead>\n<tr>\n<th>DB 이름</th>\n<th>특징</th>\n<th>사용 케이스</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Chroma</strong></td>\n<td>Python 기반 오픈소스, 설치 간단</td>\n<td>프로토타입, 실습용</td>\n</tr>\n<tr>\n<td><strong>Pinecone</strong></td>\n<td>클라우드 기반, 확장성 우수</td>\n<td>상용 서비스</td>\n</tr>\n<tr>\n<td><strong>Weaviate</strong></td>\n<td>GraphQL 지원, 다양한 벡터 검색</td>\n<td>복합 검색</td>\n</tr>\n<tr>\n<td><strong>Qdrant</strong></td>\n<td>Rust 기반, 고성능</td>\n<td>대용량 처리</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"5-4-chroma-선택-이유\">5-4 Chroma 선택 이유</h4>\n<p>실습에서 <strong>Chroma</strong>를 선택한 이유:</p>\n<ul>\n<li>Python 기반의 오픈소스 라이브러리로 <strong>설치 과정이 단순</strong></li>\n<li>별도의 서버를 띄우거나 복잡한 설정 없이 <strong>몇 줄의 코드만으로 벡터 DB 구축 가능</strong></li>\n<li>빠르게 개념을 익히고 간단한 환경에서 직접 체험하기에 적합</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># Chroma 설치</span>\npip <span class=\"token function\">install</span> chromadb</code></pre></div>\n<h2 id=\"6️-실습코드-1---vector-db-구축\">6️⃣ 실습코드 1 - Vector DB 구축</h2>\n<h4 id=\"6-1-전체-흐름-요약\">6-1 전체 흐름 요약</h4>\n<ul>\n<li><strong>초기화</strong>: 데이터베이스와 컬렉션을 초기화하여 영구 저장소 준비</li>\n<li><strong>데이터 로드</strong>: 지정된 폴더에서 텍스트 파일들을 불러옴</li>\n<li><strong>전처리</strong>: 각 텍스트 파일을 일정 길이의 청크로 분할하여 문맥 유지</li>\n<li><strong>임베딩 생성 및 저장</strong>: 각 청크에 대해 OpenAI 임베딩을 생성하고 벡터 DB에 저장</li>\n</ul>\n<h4 id=\"6-2-build_vector_dbpy-구현\">6-2 build_vector_db.py 구현</h4>\n<h5>환경 설정 및 초기화</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">from</span> openai <span class=\"token keyword\">import</span> OpenAI\n<span class=\"token keyword\">import</span> chromadb\n<span class=\"token keyword\">from</span> chromadb<span class=\"token punctuation\">.</span>config <span class=\"token keyword\">import</span> Settings\n<span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv\n\n<span class=\"token comment\"># 환경 변수 로드하여 API 키 가져오고 OpenAI 클라이언트 초기화</span>\nload_dotenv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\napi_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\nclient <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span></code></pre></div>\n<h5>DB 초기화 함수</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">init_db</span><span class=\"token punctuation\">(</span>db_path<span class=\"token operator\">=</span><span class=\"token string\">\"./chroma_db\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Vector DB 초기화 및 컬렉션 생성\"\"\"</span>\n    dbclient <span class=\"token operator\">=</span> chromadb<span class=\"token punctuation\">.</span>PersistentClient<span class=\"token punctuation\">(</span>path<span class=\"token operator\">=</span>db_path<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># rag_collection이라는 데이터 컬렉션 생성</span>\n    collection <span class=\"token operator\">=</span> dbclient<span class=\"token punctuation\">.</span>create_collection<span class=\"token punctuation\">(</span>\n        name<span class=\"token operator\">=</span><span class=\"token string\">\"rag_collection\"</span><span class=\"token punctuation\">,</span>\n        get_or_create<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> dbclient<span class=\"token punctuation\">,</span> collection</code></pre></div>\n<h5>텍스트 파일 로딩</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">load_text_files</span><span class=\"token punctuation\">(</span>folder_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"지정된 폴더에서 모든 .txt 파일 로드\"\"\"</span>\n    docs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> filename <span class=\"token keyword\">in</span> os<span class=\"token punctuation\">.</span>listdir<span class=\"token punctuation\">(</span>folder_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        file_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>folder_path<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> file_path<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\".txt\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">\"r\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n                text <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                docs<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> docs</code></pre></div>\n<h5>임베딩 생성</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">get_embedding</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">,</span> model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"주어진 텍스트를 임베딩 벡터로 변환\"\"\"</span>\n    response <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>embeddings<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>text<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> model<span class=\"token operator\">=</span>model<span class=\"token punctuation\">)</span>\n    embedding <span class=\"token operator\">=</span> response<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding\n    <span class=\"token keyword\">return</span> embedding</code></pre></div>\n<h5>텍스트 청킹</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">chunk_text</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">,</span> chunk_size<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">,</span> chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"원천 데이터를 청크 단위로 나누고 overlap 적용\"\"\"</span>\n    chunks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    start <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n    <span class=\"token keyword\">while</span> start <span class=\"token operator\">&lt;</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        end <span class=\"token operator\">=</span> start <span class=\"token operator\">+</span> chunk_size\n        chunk <span class=\"token operator\">=</span> text<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">:</span>end<span class=\"token punctuation\">]</span>\n        chunks<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>chunk<span class=\"token punctuation\">)</span>\n        start <span class=\"token operator\">=</span> end <span class=\"token operator\">-</span> chunk_overlap\n\n        <span class=\"token comment\"># 예외 처리</span>\n        <span class=\"token keyword\">if</span> start <span class=\"token operator\">&lt;</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            start <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n        <span class=\"token keyword\">if</span> start <span class=\"token operator\">>=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">break</span>\n\n    <span class=\"token keyword\">return</span> chunks</code></pre></div>\n<h5>메인 실행 로직</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># DB 초기화</span>\n    dbclient<span class=\"token punctuation\">,</span> collection <span class=\"token operator\">=</span> init_db<span class=\"token punctuation\">(</span><span class=\"token string\">\"./chroma_db\"</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 문서 로드</span>\n    folder_path <span class=\"token operator\">=</span> <span class=\"token string\">\"./source_data\"</span>\n    docs <span class=\"token operator\">=</span> load_text_files<span class=\"token punctuation\">(</span>folder_path<span class=\"token punctuation\">)</span>\n\n    doc_id <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> filename<span class=\"token punctuation\">,</span> text <span class=\"token keyword\">in</span> docs<span class=\"token punctuation\">:</span>\n        chunks <span class=\"token operator\">=</span> chunk_text<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">,</span> chunk_size<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">,</span> chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> chunk <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>chunks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            doc_id <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            embedding <span class=\"token operator\">=</span> get_embedding<span class=\"token punctuation\">(</span>chunk<span class=\"token punctuation\">)</span>\n\n            <span class=\"token comment\"># Vector DB에 저장</span>\n            collection<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>\n                documents<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>chunk<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 실제 청크 텍스트</span>\n                embeddings<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>embedding<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 생성된 임베딩 벡터</span>\n                metadatas<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n                    <span class=\"token string\">\"filename\"</span><span class=\"token punctuation\">:</span> filename<span class=\"token punctuation\">,</span>\n                    <span class=\"token string\">\"chunk_index\"</span><span class=\"token punctuation\">:</span> idx\n                <span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                ids<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>doc_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 고유 식별자</span>\n            <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"모든 문서가 Vector DB에 저장 완료\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"7️-실습코드-2---rag-챗봇-구현\">7️⃣ 실습코드 2 - RAG 챗봇 구현</h2>\n<h4 id=\"7-1-rag_chatbotpy-구현\">7-1 rag_chatbot.py 구현</h4>\n<h5>환경 설정 및 DB 연결</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">from</span> openai <span class=\"token keyword\">import</span> OpenAI\n<span class=\"token keyword\">from</span> build_vector_db <span class=\"token keyword\">import</span> get_embedding\n<span class=\"token keyword\">import</span> chromadb\n<span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv\n\nload_dotenv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndbclient <span class=\"token operator\">=</span> chromadb<span class=\"token punctuation\">.</span>PersistentClient<span class=\"token punctuation\">(</span>path<span class=\"token operator\">=</span><span class=\"token string\">\"./chroma_db\"</span><span class=\"token punctuation\">)</span>\ncollection <span class=\"token operator\">=</span> dbclient<span class=\"token punctuation\">.</span>get_or_create_collection<span class=\"token punctuation\">(</span><span class=\"token string\">\"rag_collection\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h5>문서 검색 함수</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">retrieve</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"쿼리를 임베딩하여 가장 유사한 top-k개 문서 검색\"\"\"</span>\n    query_embedding <span class=\"token operator\">=</span> get_embedding<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Vector DB에서 유사한 문서 검색</span>\n    results <span class=\"token operator\">=</span> collection<span class=\"token punctuation\">.</span>query<span class=\"token punctuation\">(</span>\n        query_embeddings<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>query_embedding<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        n_results<span class=\"token operator\">=</span>top_k\n    <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> results</code></pre></div>\n<h5>RAG 기반 답변 생성</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">generate_answer_with_context</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    RAG 기반 답변 생성 프로세스:\n    1) 쿼리에 대해 Vector DB에서 top_k개 문서 검색\n    2) 검색된 문서들을 context로 구성\n    3) Context와 함께 GPT에 프롬프트 전달\n    4) 최종 답변 반환\n    \"\"\"</span>\n\n    <span class=\"token comment\"># 1. 관련 문서 검색</span>\n    results <span class=\"token operator\">=</span> retrieve<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token punctuation\">)</span>\n    found_docs <span class=\"token operator\">=</span> results<span class=\"token punctuation\">[</span><span class=\"token string\">\"documents\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    found_metadatas <span class=\"token operator\">=</span> results<span class=\"token punctuation\">[</span><span class=\"token string\">\"metadatas\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\"># 2. Context 구성</span>\n    context_texts <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> doc_text<span class=\"token punctuation\">,</span> meta <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>found_docs<span class=\"token punctuation\">,</span> found_metadatas<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        context_texts<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>\n            <span class=\"token string-interpolation\"><span class=\"token string\">f\"&lt;&lt;filename: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>meta<span class=\"token punctuation\">[</span><span class=\"token string\">'filename'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">>>\\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>doc_text<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span>\n        <span class=\"token punctuation\">)</span>\n    context_str <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>context_texts<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 3. 프롬프트 작성</span>\n    system_prompt <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"\n    당신은 주어진 문서 정보를 바탕으로 사용자 질문에 답변하는\n    지능형 어시스턴트입니다. 다음 원칙을 엄격히 지키세요:\n\n    1. 반드시 제공된 문서 내용에 근거해서만 답변을 작성하세요.\n    2. 문서에 언급되지 않은 내용이라면, 함부로 추측하거나 만들어내지 마세요.\n    3. 사실 관계를 명확히 기술하고, 불확실한 부분은 \"정확한 정보를 찾지 못했습니다\"라고 말하세요.\n    4. 지나치게 장황하지 않게, 간결하고 알기 쉽게 설명하세요.\n    5. 문서 출처나 연도가 중요하다면, 가능한 정확하게 전달하세요.\n    \"\"\"</span>\n\n    user_prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"아래는 검색된 문서들의 내용입니다:\n    </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>context_str<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n    질문: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>query<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"\"\"</span></span>\n\n    <span class=\"token comment\"># 4. ChatGPT 호출</span>\n    api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\n    client <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span>\n\n    response <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">.</span>completions<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n        model<span class=\"token operator\">=</span><span class=\"token string\">\"gpt-4o-mini\"</span><span class=\"token punctuation\">,</span>\n        messages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"system\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> system_prompt<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> user_prompt<span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n\n    answer <span class=\"token operator\">=</span> response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>message<span class=\"token punctuation\">.</span>content\n    <span class=\"token keyword\">return</span> answer</code></pre></div>\n<h5>비교용 일반 GPT 답변</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">generate_answer_without_context</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"RAG 없이 일반 GPT로 답변하는 함수\"\"\"</span>\n    api_key <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\n    client <span class=\"token operator\">=</span> OpenAI<span class=\"token punctuation\">(</span>api_key<span class=\"token operator\">=</span>api_key<span class=\"token punctuation\">)</span>\n\n    response <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">.</span>completions<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n        model<span class=\"token operator\">=</span><span class=\"token string\">\"gpt-4o-mini\"</span><span class=\"token punctuation\">,</span>\n        messages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"system\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"You are a helpful assistant\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> query<span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n\n    answer <span class=\"token operator\">=</span> response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>message<span class=\"token punctuation\">.</span>content\n    <span class=\"token keyword\">return</span> answer</code></pre></div>\n<h5>메인 실행 루프</h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        user_query <span class=\"token operator\">=</span> <span class=\"token builtin\">input</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"질문을 입력하세요(종료: quit): \"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> user_query<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"quit\"</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">break</span>\n\n        <span class=\"token comment\"># RAG 기반 답변</span>\n        answer <span class=\"token operator\">=</span> generate_answer_with_context<span class=\"token punctuation\">(</span>user_query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># 일반 GPT 답변 (비교용)</span>\n        <span class=\"token comment\"># answer = generate_answer_without_context(user_query)</span>\n\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"===답변===\"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>answer<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"==========\\n\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h4 id=\"7-2-검색-결과-데이터-구조\">7-2 검색 결과 데이터 구조</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># collection.query() 결과 예시</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token string\">\"documents\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">[</span>문서<span class=\"token number\">1</span><span class=\"token punctuation\">,</span> 문서<span class=\"token number\">2</span><span class=\"token punctuation\">,</span> 문서<span class=\"token number\">3</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 한 개의 쿼리에 대한 top_k 문서 리스트</span>\n  <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string\">\"metadatas\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">[</span>메타데이터<span class=\"token number\">1</span><span class=\"token punctuation\">,</span> 메타데이터<span class=\"token number\">2</span><span class=\"token punctuation\">,</span> 메타데이터<span class=\"token number\">3</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 각 문서에 해당하는 메타데이터 리스트</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"-정리\">✅ 정리</h2>\n<p><strong>RAG의 핵심 포인트</strong></p>\n<ul>\n<li>🔍 <strong>검색 기반</strong>: 외부 지식을 실시간으로 검색하여 활용</li>\n<li>📊 <strong>벡터 검색</strong>: 의미적 유사도 기반의 정확한 문서 검색</li>\n<li>🎯 <strong>맥락 제공</strong>: 검색된 문서를 맥락으로 활용한 정확한 답변 생성</li>\n<li>⚡ <strong>실시간 반영</strong>: 새로운 데이터를 즉시 활용 가능</li>\n</ul>\n<p><strong>RAG vs Fine-tuning 선택 기준</strong></p>\n<ul>\n<li><strong>RAG</strong>: 실시간 정보 업데이트, 비용 효율성, 출처 명시가 중요한 경우</li>\n<li><strong>Fine-tuning</strong>: 특정 스타일/톤 학습, 응답 속도, 일관된 행동 패턴이 중요한 경우</li>\n</ul>\n<p><strong>구현 시 고려사항</strong></p>\n<ul>\n<li><strong>청킹 전략</strong>: chunk_size와 overlap 최적화</li>\n<li><strong>벡터 DB 선택</strong>: 용량과 성능 요구사항에 맞는 DB 선택</li>\n<li><strong>임베딩 모델</strong>: 도메인에 특화된 임베딩 모델 활용</li>\n<li><strong>검색 최적화</strong>: 유사도 기준과 상위 K개 결과 수 조정</li>\n</ul>\n<p>RAG는 현재 생성형 AI의 한계를 극복하고 신뢰할 수 있는 AI 서비스를 구축하는 핵심 기술이다. 체계적인 이해와 실습을 통해 실무에서 효과적으로 활용할 수 있다.</p>","fields":{"slug":"/rag-core-concept/"},"frontmatter":{"title":"RAG의 핵심 개념과 실습","date":"2025-10-01","description":"RAG의 핵심 개념부터 벡터 DB 구축, 실제 챗봇 구현까지 Python 코드와 함께 알아보자.","pointColor":"#FF6B6B","tags":["AI"],"keywords":"RAG, 검색 증강 생성, Retrieval-Augmented Generation, 벡터 데이터베이스, Vector DB, LLM, 대형 언어 모델, 챗봇, AI, 머신러닝, 자연어 처리, NLP, Python, 임베딩, Embedding","thumbnail":{"publicURL":"/static/c4d3f090e61c211003c9351ae4baa2f3/index.png","childImageSharp":{"gatsbyImageData":{"layout":"fixed","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACNUlEQVR42pWT30/TUBTH90ca44uJL/rmi08YgQd9MEYTHzQ8SCKJmMUAQUVEkYAIE0SHEzYGpatbx7pu7Afrylra7vZjWTcFQ4Le5Obm3HPPt+f7Pd9GOGf5vk+15VI5dPiXFQmLwqBl2ewVimhaqbPLlRq5fJGJpQ3GP22g62W0YplCQe/k80HOCmpOAR5jCV90AqNpktqSSKXl4NxFU/fIyQo7aQlFybEtZdjezrCZ3Onkk8Fb02yFTISP3+tQdKmZponrur+/9qNms7Jv4wqBY1l4nneqG8dxOjXHte1ehyVbMDnzirGVOP2fC4wmdVpum7c/61yalrjyXubxegG9brAo6zxZDRiUGjScNs9TOreCmmgsztTMS/SAfWSl7DAwOsLlFwv0xQ+4u15iUWsyuLrHzViO++saV+cUlss20YTKdEJhLFlgXjN5kChx/UuVi9F5+p+NsFbxQg3jqoZSNYjpFlLjqNN6KZhs37LKtbkMqZoVanzkIe83aHmh5rsHR8RKFtl6k285LdTQ/2vs7UCvQ8MgoRvkTSeg5rGqGTQOGjhdff0TzjjTNiLI9rbbFhRVldlMBbnpYDiC15kaalbFsm1O2iwYLO0gOI5F9zJytpsFhUaLr7kq6Z0sCUU/BXSusf/8FV1ttE3Ghwa5MzTJ04kZ7o1MIdVtemz+GVCIEHA29ZFHNy7wbvghH5beMDAc5fZC+v8B/e5jSc+TXFtCSm+xm8+SkmW+Z3Idzc6j/AuvdsxSQ8j9jAAAAABJRU5ErkJggg=="},"backgroundColor":"transparent","images":{"fallback":{"src":"/static/c4d3f090e61c211003c9351ae4baa2f3/1b037/index.png","srcSet":"/static/c4d3f090e61c211003c9351ae4baa2f3/1b037/index.png 568w","sizes":"568px"},"sources":[{"srcSet":"/static/c4d3f090e61c211003c9351ae4baa2f3/db111/index.webp 568w","type":"image/webp","sizes":"568px"}]},"width":1200,"height":799},"fixed":{"src":"/static/c4d3f090e61c211003c9351ae4baa2f3/0030e/index.png"}}}}},"previous":{"fields":{"slug":"/prompt-engineering-basic/"},"frontmatter":{"title":"프롬프트 엔지니어링 기초 - AI와 효과적으로 소통하는 방법"}},"next":{"fields":{"slug":"/make-huggingface-pipeline/"},"frontmatter":{"title":"허깅페이스로 파이프라인을 만들어보자 - 트랜스포머 모델 활용 가이드"}}},"pageContext":{"id":"4490516c-c3e3-53b6-9172-49cc2438814e","previousPostId":"3c29a233-debe-56e4-b36e-a5cf9faa85a4","nextPostId":"57e1e1c7-de64-5a7e-8c11-9c6b7f4ccd99"}},"staticQueryHashes":["736397157"],"slicesMap":{}}